<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>高性能服务器设计 | ZiWeeNote</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/3.0.3/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">高性能服务器设计</h1><a id="logo" href="/.">ZiWeeNote</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">高性能服务器设计</h1><div class="post-meta">Feb 3, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#xx"><span class="toc-number">1.</span> <span class="toc-text">xx</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#首先简单说一下服务器模型"><span class="toc-number">2.</span> <span class="toc-text">首先简单说一下服务器模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#多进程模型-对每个连接fork一个子进程"><span class="toc-number">2.1.</span> <span class="toc-text">多进程模型.对每个连接fork一个子进程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多线程模型"><span class="toc-number">2.2.</span> <span class="toc-text">多线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#事件驱动模型"><span class="toc-number">2.3.</span> <span class="toc-text">事件驱动模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#顺便谈下select-poll-epoll"><span class="toc-number">2.4.</span> <span class="toc-text">顺便谈下select/poll epoll</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#select和poll基本类似"><span class="toc-number">2.4.1.</span> <span class="toc-text">select和poll基本类似</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#epoll在前两者的基础上有哪些优势"><span class="toc-number">2.4.2.</span> <span class="toc-text">epoll在前两者的基础上有哪些优势</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#重新回来思考对服务器性能的影响点"><span class="toc-number">3.</span> <span class="toc-text">重新回来思考对服务器性能的影响点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据拷贝"><span class="toc-number">3.1.</span> <span class="toc-text">数据拷贝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#上下文-环境切换（Context-Switches）"><span class="toc-number">3.2.</span> <span class="toc-text">上下文/环境切换（Context Switches）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#内存分配（Memory-Allocator）"><span class="toc-number">3.3.</span> <span class="toc-text">内存分配（Memory Allocator）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#锁竞争（Lock-Contention）"><span class="toc-number">3.4.</span> <span class="toc-text">锁竞争（Lock Contention）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#其他方面"><span class="toc-number">3.5.</span> <span class="toc-text">其他方面</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="xx"><a href="#xx" class="headerlink" title="xx"></a>xx</h1><p>最近在实习,被安排做一个处理8583报文的服务端程序<code>参考github.com/ZiWee/cupad</code>.完成一个大致功能的demo后被老大问到性能测试和压力测试,开始思考高性能服务器设计的问题了.</p>
<h1 id="首先简单说一下服务器模型"><a href="#首先简单说一下服务器模型" class="headerlink" title="首先简单说一下服务器模型"></a>首先简单说一下服务器模型</h1><p>也就是常说的几种</p>
<h2 id="多进程模型-对每个连接fork一个子进程"><a href="#多进程模型-对每个连接fork一个子进程" class="headerlink" title="多进程模型.对每个连接fork一个子进程"></a>多进程模型.对每个连接fork一个子进程</h2><p>多进程模型适用于单个客户服务需要消耗较多的 CPU 资源，例如需要进行大规模或长时间的数据运算或文件访问。<br>多进程模型具有较好的安全性。</p>
<h2 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h2><p>和多进程相比，由于进程消耗的资源比线程大的多，因此，在需要为较多客户端服务的时候，优先使用多线程。<br>可拓展线程池</p>
<h2 id="事件驱动模型"><a href="#事件驱动模型" class="headerlink" title="事件驱动模型"></a>事件驱动模型</h2><p>事件驱动模型使用IO复用，在每一个执行周期都会探测一次或一组事件，一个特定的事件会触发某个特定的响应。<br>相比其他模型，事件驱动模型优点是只用单线程执行，占用资源少，不消耗太多 CPU，同时能够为多客户端提供服务。缺点是程序逻辑复杂，编程复杂性较高。<br>参考select,poll,epoll</p>
<h2 id="顺便谈下select-poll-epoll"><a href="#顺便谈下select-poll-epoll" class="headerlink" title="顺便谈下select/poll epoll"></a>顺便谈下select/poll epoll</h2><h3 id="select和poll基本类似"><a href="#select和poll基本类似" class="headerlink" title="select和poll基本类似"></a>select和poll基本类似</h3><ol>
<li>均是在用户空间有个关注集合</li>
<li>内核空间同时有个该集合的备份</li>
<li>每个执行周期在内核空间对整个集合进行一次探测</li>
<li>对集合中有事件的描述字进行标记</li>
<li>然后把整个集合给用户空间</li>
<li>select和poll大致只有调用接口不同而已吧(可能我理解不够深入)</li>
</ol>
<h3 id="epoll在前两者的基础上有哪些优势"><a href="#epoll在前两者的基础上有哪些优势" class="headerlink" title="epoll在前两者的基础上有哪些优势"></a>epoll在前两者的基础上有哪些优势</h3><ol>
<li>内核空间和用户空间之间采用共享存储</li>
<li>关注集合仅有一个,而不是用户空间内核空间两份拷贝</li>
<li>出现事件时,仅返回集合中有事件产生的描述字</li>
</ol>
<h1 id="重新回来思考对服务器性能的影响点"><a href="#重新回来思考对服务器性能的影响点" class="headerlink" title="重新回来思考对服务器性能的影响点"></a>重新回来思考对服务器性能的影响点</h1><p>大致总结为4点:</p>
<ol>
<li>数据拷贝</li>
<li>环境切换</li>
<li>内存分配</li>
<li>锁竞争</li>
</ol>
<h2 id="数据拷贝"><a href="#数据拷贝" class="headerlink" title="数据拷贝"></a>数据拷贝</h2><ol>
<li>很可能你调用的库或驱动的代码会进行数据拷贝.</li>
<li>“程序I/O”在计算机上到底指什么? 好好思考一下。 </li>
<li>哈希函数是另外一个可能产生数据拷贝的地方，在这里能看到访问内存时的拷贝和更多计算上的消耗。</li>
<li>有一种可以避免数据拷贝的方法是使用buffer的描述符（或者buffer chains的描述符）来取代直接使用buffer指针，每个buffer描述符应该由以下元素组成：<blockquote>
<p>一个指向buffer的指针和整个buffer的长度<br>一个指向buffer中真实数据的指针和真实数据的长度，或者长度的偏移<br>以双向链表的形式提供指向其它buffer的指针<br>一个引用计数</p>
<p>ngx_buf_t即是该种设计</p>
<p>但也有些问题:</p>
<ol>
<li>参考链表的常见问题,中间增加buffer/搜索/一块块的释放buffer,均需要O(n)的时间复杂度来遍历.</li>
<li>通过引用来标示拷贝.对部分buffer增加引用技术则比较困难。而分割，组合chains会让人立马崩溃。</li>
<li>数据块较大时适合用该技术.</li>
</ol>
</blockquote>
</li>
</ol>
<h2 id="上下文-环境切换（Context-Switches）"><a href="#上下文-环境切换（Context-Switches）" class="headerlink" title="上下文/环境切换（Context Switches）"></a>上下文/环境切换（Context Switches）</h2><ol>
<li>系统更多的时间都花费在线程切换上，而不是花在真正做有用工作的线程上。</li>
<li>引起环境切换的第一个原因往往是活跃线程数比CPU个数多。</li>
<li>随着活跃线程数相对于CPU个数的增加，上下文切换的次数也在增加，如果你够幸运，这种增长是线性的，但更常见是指数增长。</li>
<li>这个简单的事实解释了为什么每个连接对应一个单独线程的多线程设计模式的可伸缩性更差。对于一个可伸缩性的系统来说，限制活跃线程数少于或等于CPU个数是更有实际意义的方案。</li>
<li>但如果只使用一个活跃线程，虽然这种方案避免了环境争用，同时也避免了锁，但它不能有效利用多CPU在增加总吞吐量上的价值，因此除非程序无CPU限制（non-CPU-bound），(通常是网络I/O限制 network-I/O-bound)，应该继续使用更实际的方案。</li>
</ol>
<p>一个有适量线程的程序首先要考虑的事情是规划出如何创建一个线程去管理多连接。这通常意味着前置一个select/poll,异步I/O，信号或者完成端口，而后台使用一个事件驱动的程序框架。关于哪种前置API是最好的有很多争论。 Dan Kegel的C10K问题在这个领域是一篇不错的论文。个人认为，select/poll和信号通常是一种丑陋的方案，因此我更倾向于使用AIO或者完成端口，但是实际上它并不会好太多。也许除了select()，它们都还不错。所以不要花太多精力去探索前置系统最外层内部到底发生了什么。</p>
<p>对于最简单的多线程事件驱动服务器的概念模型, 其内部有一个请求缓存队列，客户端请求被一个或者多个监听线程获取后放到队列里，然后一个或者多个工作线程从队列里面取出请求并处理。从概念上来说，这是一个很好的模型，有很多用这种方式来实现他们的代码。这会产生什么问题吗？引起环境切换的第二个原因是把对请求的处理从一个线程转移到另一个线程。有些人甚至把对请求的回应又切换回最初的线程去做，这真是雪上加霜，因为每一个请求至少引起了2次环境切换。把一个请求从监听线程转换到成工作线程，又转换回监听线程的过程中，使用一种“平滑”的方法来避免环境切换是非常重要的。此时，是否把连接请求分配到多个线程，或者让所有线程依次作为监听线程来服务每个连接请求，反而不重要了。</p>
<p>即使在将来,也不可能有办法知道在服务器中同一时刻会有多少激活线程.毕竟，每时每刻都可能有请求从任意连接发送过来，一些进行特殊任务的“后台”线程也会在任意时刻被唤醒。那么如果你不知道当前有多少线程是激活的，又怎么能够限制激活线程的数量呢？根据我的经验，最简单同时也是最有效的方法之一是：用一个老式的带计数的信号量，每一个线程执行的时候就先持有信号量。如果信号量已经到了最大值，那些处于监听模式的线程被唤醒的时候可能会有一次额外的环境切换,(监听线程被唤醒是因为有连接请求到来, 此时监听线程持有信号量时发现信号量已满,所以即刻休眠), 接着它就会被阻塞在这个信号量上，一旦所有监听模式的线程都这样阻塞住了，那么它们就不会再竞争资源了，直到其中一个线程释放信号量，这样环境切换对系统的影响就可以忽略不计。更主要的是，这种方法使大部分时间处于休眠状态的线程避免在激活线程数中占用一个位置，这种方式比其它的替代方案更优雅。</p>
<p>一旦处理请求的过程被分成两个阶段(监听和工作)，那么更进一步，这些处理过程在将来被分成更多的阶段(更多的线程)就是很自然的事了。最简单的情况是一个完整的请求先完成第一步,然后是第二步(比如回应)。然而实际会更复杂：一个阶段可能产生出两个不同执行路径，也可能只是简单的生成一个应答(例如返回一个缓存的值)。由此每个阶段都需要知道下一步该如何做，根据阶段分发函数的返回值有三种可能的做法：</p>
<p>　　l  请求需要被传递到另外一个阶段（返回一个描述符或者指针）</p>
<p>　　l  请求已经完成（返回ok）</p>
<p>　　l  请求被阻塞(返回”请求阻塞”)。这和前面的情况一样，阻塞到直到别的线程释放资源</p>
<p>　　应该注意到在这种模式下，对阶段的排队是在一个线程内完成的，而不是经由两个线程中完成。这样避免不断把请求放在下一阶段的队列里，紧接着又从该队列取出这个请求来执行。这种经由很多活动队列和锁的阶段很没必要。</p>
<p>　　这种把一个复杂的任务分解成多个较小的互相协作的部分的方式，看起来很熟悉，这是因为这种做法确实很老了。我的方法，源于CAR在1978年发明的”通信序列化进程”(Communicating Sequential Processes CSP)，它的基础可以上溯到1963时的Per Brinch Hansen and Matthew Conway–在我出生之前！然而，当Hoare创造出CSP这个术语的时候，他说的“进程”是抽象数学意义上的进程，而且，这个CSP术语中的进程和操作系统中同名的那个进程并没有关系。依我看来，这种在操作系统提供的单个线程之内，实现类似多线程一样协同并发工作的CSP的方法，在可扩展性方面让很多人头疼。</p>
<p>　　一个实际的例子是，Matt Welsh的SEDA，这个例子表明分段执行的(stage-execution)思想朝着一个比较合理的方向发展。SEDA是一个很好的“server Aarchitecture done right”的例子，值得把它的特性评论一下：</p>
<p>　　1.   SEDA的批处理倾向于强调一个阶段处理多个请求，而我的方式倾向于强调一个请求分成多个阶段处理。</p>
<p>　　2.   在我看来SEDA的一个重大缺陷是给每个阶段申请一个独立的在加载响应阶段只进行线程“后台”重分配的线程池。结果，原因1和原因2引起的环境切换仍然很多。</p>
<p>　　3.   在纯技术的研究项目中，在Java中使用SEDA是有用的，然而在实际应用场合，我觉得这种方法很少被选择。</p>
<h2 id="内存分配（Memory-Allocator）"><a href="#内存分配（Memory-Allocator）" class="headerlink" title="内存分配（Memory Allocator）"></a>内存分配（Memory Allocator）</h2><p>　　申请和释放内存是应用程序中最常见的操作, 因此发明了许多聪明的技巧使得内存的申请效率更高。然而再聪明的方法也不能弥补这种事实:在很多场合中，一般的内存分配方法非常没有效率。所以为了减少向系统申请内存，我有三个建议。</p>
<p>　　建议一是使用预分配。我们都知道由于使用静态分配而导致对程序的功能加上人为限制是一种糟糕的设计。但是还是有许多其它很不错的预分配方案。通常认为，通过系统一次性分配内存要比分开几次分配要好，即使这样做在程序中浪费了某些内存。如果能够确定在程序中会有几项内存使用，在程序启动时预分配就是一个合理的选择。即使不能确定，在开始时为请求句柄预分配可能需要的所有内存也比在每次需要一点的时候才分配要好。通过系统一次性连续分配多项内存还能极大减少错误处理代码。在内存比较紧张时，预分配可能不是一个好的选择，但是除非面对最极端的系统环境，否则预分配都是一个稳赚不赔的选择。</p>
<p>　　建议二是使用一个内存释放分配的lookaside list(监视列表或者后备列表)。基本的概念是把最近释放的对象放到链表里而不是真的释放它，当不久再次需要该对象时，直接从链表上取下来用，不用通过系统来分配。使用lookaside list的一个额外好处是可以避免复杂对象的初始化和清理.</p>
<p>　　通常，让lookaside list不受限制的增长，即使在程序空闲时也不释放占用的对象是个糟糕的想法。在避免引入复杂的锁或竞争情况下，不定期的“清扫”非活跃对象是很有必要的。一个比较妥当的办法是,让lookaside list由两个可以独立锁定的链表组成：一个”新链”和一个”旧链”.使用时优先从”新”链分配，然后最后才依靠”旧”链。对象总是在”新”链上被释放。清除线程则按如下规则运行：</p>
<p>　　1.   锁住两个链</p>
<p>　　2.   保存旧链的头结点</p>
<p>　　3.   把前一个新链挂到旧链的前头</p>
<p>　　4.   解锁</p>
<p>　　5.   在空闲时通过第二步保存的头结点开始释放旧链的所有对象。</p>
<p>　　使用了这种方式的系统中，对象只有在真的没用时才会释放，释放至少延时一个清除间隔期(指清除线程的运行间隔)，但同常不会超过两个间隔期。清除线程不会和普通线程发生锁竞争。理论上来说，同样的方法也可以应用到请求的多个阶段，但目前我还没有发现有这么用的。</p>
<p>　　使用lookaside lists有一个问题是，保持分配对象需要一个链表指针(链表结点)，这可能会增加内存的使用。但是即使有这种情况，使用它带来的好处也能够远远弥补这些额外内存的花销。</p>
<p>　　第三条建议与我们还没有讨论的锁有关系。先抛开它不说。即使使用lookaside list,内存分配时的锁竞争也常常是最大的开销。解决方法是使用线程私有的lookasid list, 这样就可以避免多个线程之间的竞争。更进一步，每个处理器一个链会更好，但这样只有在非抢先式线程环境下才有用。基于极端考虑，私有lookaside list甚至可以和一个共用的链工作结合起来使用。</p>
<h2 id="锁竞争（Lock-Contention）"><a href="#锁竞争（Lock-Contention）" class="headerlink" title="锁竞争（Lock Contention）"></a>锁竞争（Lock Contention）</h2><p>　　高效率的锁是非常难规划的, 以至于我把它称作卡律布狄斯和斯库拉(参见附录)。一方面, 锁的简单化(粗粒度锁)会导致并行处理的串行化,因而降低了并发的效率和系统可伸缩性; 另一方面, 锁的复杂化(细粒度锁)在空间占用上和操作时的时间消耗上都可能产生对性能的侵蚀。偏向于粗粒度锁会有死锁发生，而偏向于细粒度锁则会产生竞争。在这两者之间，有一个狭小的路径通向正确性和高效率，但是路在哪里？</p>
<p>　　由于锁倾向于对程序逻辑产生束缚，所以如果要在不影响程序正常工作的基础上规划出锁方案基本是不可能的。这也就是人们为什么憎恨锁，并且为自己设计的不可扩展的单线程方案找借口了。</p>
<p>　　几乎我们每个系统中锁的设计都始于一个”锁住一切的超级大锁”，并寄希望于它不会影响性能，当希望落空时(几乎是必然), 大锁被分成多个小锁，然后我们继续祷告(性能不会受影响)，接着，是重复上面的整个过程(许多小锁被分成更小的锁), 直到性能达到可接受的程度。通常，上面过程的每次重复都回增加大于20%-50%的复杂性和锁负荷，并减少5%-10%的锁竞争。最终结果是取得了适中的效率，但是实际效率的降低是不可避免的。设计者开始抓狂:”我已经按照书上的指导设计了细粒度锁，为什么系统性能还是很糟糕?”</p>
<p>　　在我的经验里，上面的方法从基础上来说就不正确。设想把解决方案当成一座山，优秀的方案表示山顶，糟糕的方案表示山谷。上面始于”超级锁”的解决方案就好像被形形色色的山谷，凹沟，小山头和死胡同挡在了山峰之外的登山者一样，是一个典型的糟糕爬山法；从这样一个地方开始登顶，还不如下山更容易一些。那么登顶正确的方法是什么？</p>
<p>　　首要的事情是为你程序中的锁形成一张图表，有两个轴：</p>
<p>　　l  图表的纵轴表示代码。如果你正在应用剔出了分支的阶段架构(指前面说的为请求划分阶段)，你可能已经有这样一张划分图了，就像很多人见过的OSI七层网络协议架构图一样。</p>
<p>　　l  图表的水平轴表示数据集。在请求的每个阶段都应该有属于该阶段需要的数据集。</p>
<p>　　现在，你有了一张网格图，图上每个单元格表示一个特定阶段需要的特定数据集。下面是应该遵守的最重要的规则：两个请求不应该产生竞争，除非它们在同一个阶段需要同样的数据集。如果你严格遵守这个规则，那么你已经成功了一半。</p>
<p>　　一旦你定义出了上面那个网格图，在你的系统中的每种类型的锁就都可以被标识出来了。你的下一个目标是确保这些标识出来的锁尽可能在两个轴之间均匀的分布,这部分工作是和具体应用相关的。你得像个钻石切割工一样，根据你对程序的了解，找出请求阶段和数据集之间的自然“纹理线”。有时候它们很容易发现，有时候又很难找出来，此时需要不断回顾来发现它。在程序设计时，把代码分隔成不同阶段是很复杂的事情，我也没有好的建议，但是对于数据集的定义，有一些建议给你：</p>
<p>　　l  如果你能对请求按顺序编号，或者能对请求进行哈希，或者能把请求和事物ID关联起来，那么根据这些编号或者ID就能对数据更好的进行分隔。</p>
<p>　　l  有时，基于数据集的资源最大化利用，把请求动态的分配给数据，相对于依据请求的固有属性来分配会更有优势。就好像现代CPU的多个整数运算单元知道把请求分离一样。</p>
<p>　　l  确定每个阶段指定的数据集是不一样的是非常有用的，以便保证一个阶段争夺的数据在另外阶段不会争夺。</p>
<p>　　如果你在纵向和横向上把“锁空间(这里实际指锁的分布)” 分隔了，并且确保了锁均匀分布在网格上，那么恭喜你获得了一个好方案。现在你处在了一个好的登山点，打个比喻，你面有了一条通向顶峰的缓坡，但你还没有到山顶。现在是时候对锁竞争进行统计，看看该如何改进了。以不同的方式分隔阶段和数据集，然后统计锁竞争，直到获得一个满意的分隔。当你做到这个程度的时候，那么无限风景将呈现在你脚下。</p>
<h2 id="其他方面"><a href="#其他方面" class="headerlink" title="其他方面"></a>其他方面</h2><p>　　我已经阐述完了影响性能的四个主要方面。然而还有一些比较重要的方面需要说一说，大多数都可归结于你的平台或系统环境：</p>
<p>　　l  你的存储子系统在大数据读写和小数据读写，随即读写和顺序读写方面是如何进行？在预读和延迟写入方面做得怎样？</p>
<p>　　l  你使用的网络协议效率如何？是否可以通过修改参数改善性能？是否有类似于TCP_CORK, MSG_PUSH,Nagle-toggling算法的手段来避免小消息产生？</p>
<p>　　l  你的系统是否支持Scatter-Gather I/O(例如readv/writev)? 使用这些能够改善性能，也能避免使用缓冲链(见第一节数据拷贝的相关叙述)带来的麻烦。（说明：在dma传输数据的过程中，要求源物理地址和目标物理地址必须是连续的。但在有的计算机体系中，如IA，连续的存储器地址在物理上不一定是连续的，则dma传输要分成多次完成。如果传输完一块物理连续的数据后发起一次中断，同时主机进行下一块物理连续的传输，则这种方式即为block dma方式。scatter/gather方式则不同，它是用一个链表描述物理不连续的存储器，然后把链表首地址告诉dma master。dma master传输完一块物理连续的数据后，就不用再发中断了，而是根据链表传输下一块物理连续的数据，最后发起一次中断。很显然 scatter/gather方式比block dma方式效率高）</p>
<p>　　l  你的系统的页大小是多少？高速缓存大小是多少？向这些大小边界进行对起是否有用？系统调用和上下文切换花的代价是多少？</p>
<p>　　l  你是否知道锁原语的饥饿现象？你的事件机制有没有”惊群”问题?你的唤醒/睡眠机制是否有这样糟糕的行为: 当X唤醒了Y, 环境立刻切换到了Y,但是X还有没完成的工作?</p>
<p>　　我在这里考虑的了很多方面，相信你也考虑过。在特定情况下，应用这里提到的某些方面可能没有价值，但能考虑这些因素的影响还是有用的。如果在系统手册中，你没有找到这些方面的说明，那么就去努力找出答案。写一个测试程序来找出答案；不管怎样，写这样的测试代码都是很好的技巧锻炼。如果你写的代码在多个平台上都运行过，那么把这些相关的代码抽象为一个平台相关的库，将来在某个支持这里提到的某些功能的平台上，你就赢得了先机。</p>
<p>　　对你的代码,“知其所以然”, 弄明白其中高级的操作, 以及在不同条件下的花销.这不同于传统的性能分析, 不是关于具体的实现,而是关乎设计. 低级别的优化永远是蹩脚设计的最后救命稻草.</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2016/02/03/高性能服务器设计/" data-id="cinibzrw3000c88rfvek8e3ua" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2016/03/22/openwrt编译未生成factory.bin和sysupdate.bin原因/" class="pre">openwrt编译未生成factory.bin和sysupdate.bin原因</a><a href="/2016/01/04/我的开发环境配置/" class="next">我的开发环境配置</a></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/04/27/mosquitto简介-安装-使用-测试/">mosquitto简介/安装/使用/测试</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/26/markdownpad2在WIN10下无法实时预览/">markdownpad2在WIN10下无法实时预览</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/25/802-11协议与用户行为/">路由器与用户行为</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/25/nginx学习/">nginx学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/21/centos-64bit-inet-ntoa后使用printf段错误/">centos-64bit inet_ntoa后使用printf段错误</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/07/cJSON源码学习/">cJSON源码学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/07/makefile学习/">makefile学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/05/tinyhttpd源码学习/">tinyhttpd源码学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/26/常用文本处理/">常用文本处理</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/26/通过hostapd对用户wifi行为记录/">通过hostapd对用户wifi行为记录</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">ZiWeeNote.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>